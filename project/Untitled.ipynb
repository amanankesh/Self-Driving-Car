{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W, stride):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding='VALID')\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 66, 200, 3])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "x_image = x\n",
    "\n",
    "#first convolutional layer\n",
    "W_conv1 = weight_variable([5, 5, 3, 24])\n",
    "b_conv1 = bias_variable([24])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1, 2) + b_conv1)\n",
    "\n",
    "#second convolutional layer\n",
    "W_conv2 = weight_variable([5, 5, 24, 36])\n",
    "b_conv2 = bias_variable([36])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2, 2) + b_conv2)\n",
    "\n",
    "#third convolutional layer\n",
    "W_conv3 = weight_variable([5, 5, 36, 48])\n",
    "b_conv3 = bias_variable([48])\n",
    "\n",
    "h_conv3 = tf.nn.relu(conv2d(h_conv2, W_conv3, 2) + b_conv3)\n",
    "\n",
    "#fourth convolutional layer\n",
    "W_conv4 = weight_variable([3, 3, 48, 64])\n",
    "b_conv4 = bias_variable([64])\n",
    "\n",
    "h_conv4 = tf.nn.relu(conv2d(h_conv3, W_conv4, 1) + b_conv4)\n",
    "\n",
    "#fifth convolutional layer\n",
    "W_conv5 = weight_variable([3, 3, 64, 64])\n",
    "b_conv5 = bias_variable([64])\n",
    "\n",
    "h_conv5 = tf.nn.relu(conv2d(h_conv4, W_conv5, 1) + b_conv5)\n",
    "\n",
    "\n",
    "\n",
    "#FCL 1\n",
    "W_fc1 = weight_variable([1152, 1164])\n",
    "b_fc1 = bias_variable([1164])\n",
    "\n",
    "h_conv5_flat = tf.reshape(h_conv5, [-1, 1152])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_conv5_flat, W_fc1) + b_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "#FCL 2\n",
    "W_fc2 = weight_variable([1164, 100])\n",
    "b_fc2 = bias_variable([100])\n",
    "\n",
    "h_fc2 = tf.nn.relu(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "h_fc2_drop = tf.nn.dropout(h_fc2, keep_prob)\n",
    "\n",
    "#FCL 3\n",
    "W_fc3 = weight_variable([100, 50])\n",
    "b_fc3 = bias_variable([50])\n",
    "\n",
    "h_fc3 = tf.nn.relu(tf.matmul(h_fc2_drop, W_fc3) + b_fc3)\n",
    "\n",
    "h_fc3_drop = tf.nn.dropout(h_fc3, keep_prob)\n",
    "\n",
    "#FCL 3\n",
    "W_fc4 = weight_variable([50, 10])\n",
    "b_fc4 = bias_variable([10])\n",
    "\n",
    "h_fc4 = tf.nn.relu(tf.matmul(h_fc3_drop, W_fc4) + b_fc4)\n",
    "\n",
    "h_fc4_drop = tf.nn.dropout(h_fc4, keep_prob)\n",
    "\n",
    "#Output\n",
    "W_fc5 = weight_variable([10, 1])\n",
    "b_fc5 = bias_variable([1])\n",
    "\n",
    "y = tf.multiply(tf.atan(tf.matmul(h_fc4_drop, W_fc5) + b_fc5), 2) #scale the atan output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.core.protobuf import saver_pb2\n",
    "import driving_data\n",
    "import model\n",
    "\n",
    "LOGDIR = './save'\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "L2NormConst = 0.001\n",
    "\n",
    "train_vars = tf.trainable_variables()\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(tf.subtract(model.y_, model.y))) + tf.add_n([tf.nn.l2_loss(v) for v in train_vars]) * L2NormConst\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "# create a summary to monitor cost tensor\n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "# merge all summaries into a single op\n",
    "merged_summary_op =  tf.summary.merge_all()\n",
    "\n",
    "saver = tf.train.Saver(write_version = saver_pb2.SaverDef.V1)\n",
    "\n",
    "# op to write logs to Tensorboard\n",
    "logs_path = './logs'\n",
    "summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 100\n",
    "\n",
    "# train over the dataset about 30 times\n",
    "for epoch in range(epochs):\n",
    "  for i in range(int(driving_data.num_images/batch_size)):\n",
    "    xs, ys = driving_data.LoadTrainBatch(batch_size)\n",
    "    train_step.run(feed_dict={model.x: xs, model.y_: ys, model.keep_prob: 0.8})\n",
    "    if i % 10 == 0:\n",
    "      xs, ys = driving_data.LoadValBatch(batch_size)\n",
    "      loss_value = loss.eval(feed_dict={model.x:xs, model.y_: ys, model.keep_prob: 1.0})\n",
    "      print(\"Epoch: %d, Step: %d, Loss: %g\" % (epoch, epoch * batch_size + i, loss_value))\n",
    "\n",
    "    # write logs at every iteration\n",
    "    summary = merged_summary_op.eval(feed_dict={model.x:xs, model.y_: ys, model.keep_prob: 1.0})\n",
    "    summary_writer.add_summary(summary, epoch * driving_data.num_images/batch_size + i)\n",
    "\n",
    "    if i % batch_size == 0:\n",
    "      if not os.path.exists(LOGDIR):\n",
    "        os.makedirs(LOGDIR)\n",
    "      checkpoint_path = os.path.join(LOGDIR, \"model.ckpt\")\n",
    "      filename = saver.save(sess, checkpoint_path)\n",
    "  print(\"Model saved in file: %s\" % filename)\n",
    "\n",
    "print(\"Run the command line:\\n\" \\\n",
    "          \"--> tensorboard --logdir=./logs \" \\\n",
    "          \"\\nThen open http://0.0.0.0:6006/ into your web browser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0812e-01, -1.0639e-01, -3.9186e-01, -3.6660e-01,  9.4173e-02,\n",
       "          -3.2681e-01, -2.8529e-01, -1.9983e-01, -1.2872e-01,  6.1899e-02,\n",
       "          -2.3042e-02,  4.1810e-03, -9.1592e-02,  2.3434e-01,  5.6779e-01,\n",
       "          -9.9352e-03, -3.9683e-01, -4.0369e-01,  4.0522e-01, -2.1479e-01],\n",
       "         [ 1.6082e-02,  1.0800e-01, -1.2741e-01,  1.1410e-02, -1.3198e-01,\n",
       "          -1.7007e-01,  1.9169e-02, -2.6492e-01,  7.0224e-02,  3.4116e-02,\n",
       "          -1.9191e-01, -7.8186e-02,  4.9966e-02, -3.6339e-01, -2.0549e-01,\n",
       "          -2.0830e-01, -9.5906e-02,  2.2274e-01, -2.0912e-02, -8.7921e-02],\n",
       "         [-3.3593e-01, -5.8537e-02,  2.1923e-01,  1.3347e-01, -2.9632e-01,\n",
       "          -2.9327e-02,  2.5836e-01,  4.5834e-02, -3.8109e-01, -1.4282e-01,\n",
       "           2.9012e-01, -6.1021e-02,  4.7813e-02, -1.6783e-01,  1.9012e-01,\n",
       "          -1.1615e-01, -2.8970e-01,  2.8677e-01, -6.5787e-02,  7.8702e-02]],\n",
       "\n",
       "        [[-1.3424e-01,  2.6607e-02, -2.2909e-01, -1.1644e-01,  6.3093e-02,\n",
       "          -1.3051e-01, -1.3093e-01, -6.4403e-02,  3.2155e-02,  9.8620e-02,\n",
       "          -6.3305e-02,  4.1702e-02, -8.7324e-02,  5.8120e-02,  2.3438e-01,\n",
       "          -1.2331e-01, -1.2292e-01, -9.2880e-02,  1.6144e-01, -1.2400e-01],\n",
       "         [ 4.6621e-02,  4.2635e-02, -9.0326e-02,  1.0430e-02, -9.6714e-02,\n",
       "          -8.8270e-02,  8.0269e-02, -1.6798e-01,  8.5334e-02,  8.6317e-02,\n",
       "          -2.1099e-01, -2.1303e-02,  1.3656e-02, -2.4145e-01, -9.6697e-02,\n",
       "          -1.9078e-01,  1.4081e-02,  3.7332e-02, -3.7942e-02, -1.5442e-01],\n",
       "         [-3.3633e-01,  5.9578e-02,  1.6527e-01,  1.0966e-01, -2.2242e-01,\n",
       "           2.1398e-02,  1.5871e-01,  6.5535e-02, -1.7183e-01, -6.4249e-02,\n",
       "           9.9230e-02, -4.3212e-02,  6.9664e-02, -1.7441e-01, -1.9671e-02,\n",
       "          -1.8149e-01, -9.7809e-02,  1.5506e-01,  4.3566e-04, -9.3797e-03]],\n",
       "\n",
       "        [[-1.1119e-01,  5.6048e-02, -9.4757e-02, -2.6697e-02,  2.2736e-02,\n",
       "          -9.5925e-02, -5.6300e-02, -1.3665e-02,  8.6352e-02,  9.6964e-02,\n",
       "          -7.3902e-02,  4.8554e-02, -5.5208e-02, -2.9951e-02,  9.2799e-02,\n",
       "          -1.6354e-01, -4.4668e-02, -1.1204e-02,  1.0500e-01, -1.0255e-01],\n",
       "         [ 2.6585e-02,  5.1891e-02, -4.6526e-02,  3.3297e-02, -4.5091e-02,\n",
       "          -3.6994e-02,  1.1233e-01, -6.8730e-02,  1.0160e-01,  6.7802e-02,\n",
       "          -1.4988e-01,  1.5749e-02, -1.1841e-02, -1.8630e-01, -7.4103e-02,\n",
       "          -1.8965e-01,  3.9619e-02,  3.6801e-02, -3.9790e-02, -1.7221e-01],\n",
       "         [-2.0239e-01,  6.3968e-02,  9.4011e-02,  6.9329e-02, -1.4323e-01,\n",
       "           3.2676e-02,  7.8157e-02,  3.6252e-02, -3.5388e-02, -5.2729e-02,\n",
       "           3.9194e-02, -5.3500e-03,  1.4397e-02, -1.6070e-01, -9.0606e-02,\n",
       "          -1.9172e-01, -7.2114e-02,  9.5956e-02,  1.6689e-02, -4.6203e-02]],\n",
       "\n",
       "        [[-9.1827e-02,  7.4609e-02, -3.3456e-02,  1.4007e-02,  9.7264e-03,\n",
       "          -5.5221e-02, -3.4293e-03, -4.3361e-03,  9.6756e-02,  4.9247e-02,\n",
       "          -9.1569e-02,  5.5147e-02, -4.3244e-02, -7.5558e-02,  3.7768e-03,\n",
       "          -1.7947e-01, -9.8794e-03,  3.2057e-02,  5.8632e-02, -1.1604e-01],\n",
       "         [ 1.8387e-03,  6.2673e-02, -3.5631e-02,  3.5936e-02, -7.8141e-03,\n",
       "          -3.2017e-03,  1.2509e-01, -2.6896e-02,  9.7461e-02,  5.8004e-02,\n",
       "          -1.1706e-01,  3.1677e-02, -8.0164e-03, -1.9246e-01, -5.8065e-02,\n",
       "          -1.6848e-01,  6.1048e-02,  5.5019e-02, -5.8125e-02, -1.8389e-01],\n",
       "         [-1.2524e-01,  8.8422e-02,  4.9585e-02,  3.8091e-02, -7.4581e-02,\n",
       "           4.8351e-02,  6.7332e-02,  1.9908e-02,  4.3279e-02, -3.9072e-02,\n",
       "           2.5960e-03,  1.3438e-02, -7.6454e-03, -1.6350e-01, -1.0654e-01,\n",
       "          -1.8084e-01, -3.4129e-02,  7.6455e-02,  8.8429e-03, -9.5624e-02]],\n",
       "\n",
       "        [[-7.3049e-02,  7.9814e-02, -1.1106e-02,  8.4661e-03,  2.4988e-03,\n",
       "          -1.7912e-02,  4.1779e-02, -1.8564e-02,  8.9669e-02,  1.8340e-02,\n",
       "          -1.0128e-01,  4.8997e-02, -4.5970e-02, -1.3157e-01, -2.8512e-02,\n",
       "          -1.8164e-01,  3.1175e-03,  3.7860e-02,  1.0663e-02, -1.3297e-01],\n",
       "         [-1.8098e-02,  7.4118e-02, -3.1887e-02,  1.9232e-02,  8.2137e-03,\n",
       "           1.3876e-02,  1.3181e-01,  7.7818e-03,  9.0202e-02,  2.1755e-02,\n",
       "          -1.0134e-01,  3.2988e-02, -1.2590e-03, -1.7585e-01, -6.2432e-02,\n",
       "          -1.7094e-01,  8.0224e-02,  8.2007e-02, -6.6547e-02, -1.8675e-01],\n",
       "         [-8.8663e-02,  8.2511e-02,  3.9013e-02,  1.0816e-02, -2.3861e-02,\n",
       "           4.6947e-02,  8.0546e-02,  1.3727e-02,  8.8832e-02, -2.1187e-02,\n",
       "          -5.0532e-03,  1.8593e-02, -2.2439e-02, -1.8585e-01, -9.0255e-02,\n",
       "          -1.5817e-01, -2.1953e-02,  6.7540e-02,  2.4904e-02, -1.2477e-01]]],\n",
       "       grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = nn.LSTM(10, 20, 2)\n",
    "input = torch.randn(5, 3, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "c0 = torch.randn(2, 3, 20)\n",
    "output, (hn, cn) = rnn(input, (h0, c0))\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
