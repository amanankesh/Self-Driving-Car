{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a933ad8ccfc6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0180]], grad_fn=<ReluBackward0>)\n",
      "tensor([0.0180], grad_fn=<SelectBackward>) 2.260197401046753\n",
      "tensor([30606780.], grad_fn=<SelectBackward>) 1.8965776715218944e+16\n",
      "tensor([0.], grad_fn=<SelectBackward>) 6.881675720214844\n",
      "tensor([0.], grad_fn=<SelectBackward>) 10.351865768432617\n",
      "tensor([0.], grad_fn=<SelectBackward>) 11.175758361816406\n",
      "tensor([0.], grad_fn=<SelectBackward>) 13.313314437866211\n",
      "tensor([0.], grad_fn=<SelectBackward>) 15.420353889465332\n",
      "tensor([0.], grad_fn=<SelectBackward>) 17.45132064819336\n",
      "tensor([0.], grad_fn=<SelectBackward>) 20.30356216430664\n",
      "tensor([0.], grad_fn=<SelectBackward>) 24.08241081237793\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Conv2d(3,24,(5,5),(2,2)),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Conv2d(24,36,(5,5),(2,2)),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Conv2d(36,48,(5,5),(2,2)),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Conv2d(48,64,(3,3),(1,1)),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Conv2d(64,64,(3,3),(1,1)),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Flatten(),\n",
    "                      nn.Linear(1152,1),\n",
    "                      nn.ReLU()\n",
    "                     )\n",
    "\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "learning_rate = 1e-1\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "x = torch.rand((100, 3, 66, 200))\n",
    "y = torch.rand(100,1)\n",
    "print(model(x[:1]))\n",
    "\n",
    "for t in range(10):\n",
    "    y_pred = model(x[:(t+1)*10])\n",
    "    loss = loss_fn(y_pred, y[:(t+1)*10])\n",
    "    print(y_pred[0], loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-460a3c056939>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mloss_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'sum'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m CNNmodel = nn.Sequential(nn.Conv2d(3,24,(5,5),(2,2)),\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.MSELoss(reduction = 'sum')\n",
    "learning_rate = 1e-1\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "CNNmodel = nn.Sequential(nn.Conv2d(3,24,(5,5),(2,2)),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Conv2d(24,36,(5,5),(2,2)),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Conv2d(36,48,(5,5),(2,2)),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Conv2d(48,64,(3,3),(1,1)),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Conv2d(64,64,(3,3),(1,1)),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Flatten() )\n",
    "\n",
    "FCNNmodel = nn.Sequential(nn.Linear(1164, 100),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Linear(100, 50),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Linear(50, 10),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Linear(10, 1),\n",
    "                         nn.ReLU()\n",
    "                         )\n",
    "LSTMmodel = nn.LSTM( 1152, 1164, 3, batch_first = True)\n",
    "hn = torch.randn(3, 1, 1164)\n",
    "cn = torch.randn(3, 1, 1164)\n",
    "LSTMmodel(torch.rand((1,1,1152)), (hn, cn))\n",
    "\n",
    "\n",
    "y_pred = []\n",
    "x = torch.rand((100, 3, 66, 200))\n",
    "y = torch.rand(10)\n",
    "print(y)\n",
    "for j in range(10):\n",
    "    y_pred = []\n",
    "    for i in range(10):\n",
    "        x_ = x[i].view(1,3, 66, 200)\n",
    "        x_ = CNNmodel(x_).view((1,1,1152))\n",
    "        x_, (hn, cn) = LSTMmodel(x_)\n",
    "        y_pred.append(FCNNmodel(x_.view(1164)))\n",
    "        #print(y_pred[i])\n",
    "    \n",
    "    loss = loss_fn(torch.tensor(y_pred, requires_grad = True), y )\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1324, -0.1962, -0.1969,  ..., -0.0797,  0.1958, -0.0449],\n",
       "         [-0.1257,  0.3401,  0.0651,  ...,  0.5061,  0.1147, -0.6397],\n",
       "         [ 0.0867, -0.0460, -0.0064,  ...,  0.2911, -0.0369, -0.0088],\n",
       "         ...,\n",
       "         [-0.1485,  0.3546, -0.0603,  ..., -0.4456,  0.5361, -0.1769],\n",
       "         [ 0.5419,  0.0600,  0.0106,  ..., -0.2108, -0.0815, -0.1012],\n",
       "         [ 0.4541, -0.0733, -0.0405,  ..., -0.1643, -0.5368, -0.3579]]],\n",
       "       grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = nn.LSTM(1152, 1164, 3)\n",
    "\n",
    "input = torch.randn(1, 10, 1152)\n",
    "h0 = torch.randn(3, 10, 1164)\n",
    "c0 = torch.randn(3, 10, 1164)\n",
    "output, (hn, cn) = rnn(input, (h0, c0))\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 20])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = nn.LSTM(10, 20, 2)\n",
    "input = torch.randn(1, 3, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "c0 = torch.randn(2, 3, 20)\n",
    "output, (hn, cn) = rnn(input, (h0, c0))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6549, 0.1065, 0.6089,  ..., 0.2321, 0.8988, 0.9177]]])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand((1,1,1152))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}